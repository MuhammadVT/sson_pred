{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_bin_out(row, nBins, binTimeRes):\n",
    "    \"\"\"\n",
    "    Given the prediction label, get the actual\n",
    "    output in bins by converting the label into\n",
    "    binary representation. For ex, label 2 would\n",
    "    convert to 10 and 5 to 101 and so on.\n",
    "    \"\"\"\n",
    "    # Note we need the binary format to be consistent\n",
    "    # with the actual labels, i.e., it depends on the \n",
    "    # number of bins. For example, 2 could be 10 or 010.\n",
    "    binFormtStr = '{0:0' + str(nBins) + 'b}'\n",
    "    predBinStr = binFormtStr.format(row[\"pred_label\"])\n",
    "    # Now add these into different pred bins\n",
    "    for _n, _pb in enumerate(predBinStr):\n",
    "        row[\"pbin_\" + str(_n)] = int(_pb)\n",
    "    if row[\"label\"] == 0:\n",
    "        if row[\"pred_label\"] == 0:\n",
    "            predType = \"TN\"\n",
    "        else:\n",
    "            predType = \"FP\"\n",
    "    if row[\"label\"] == 1:\n",
    "        if row[\"pred_label\"] == 1:\n",
    "            predType = \"TP\"\n",
    "        else:\n",
    "            predType = \"FN\"\n",
    "    row[\"pred_type\"] = predType\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colNames = [\"date\"]\n",
    "nBins = 1\n",
    "binRes = 90\n",
    "for _nb in range(nBins):\n",
    "    colNames += [ \"bin_\" + str(_nb) ]\n",
    "colNames += [\"label\", \"del_minutes\",\"pred_label\"]\n",
    "for _nb in range(nBins):\n",
    "    # there are 2 probs for each bin\n",
    "    # one zero prob and other 1 prob\n",
    "    colNames += [ \"prob_type_0_b_\" + str(_nb) ]\n",
    "    colNames += [ \"prob_type_1_b_\" + str(_nb) ]\n",
    "predDF = pandas.read_csv(\"../data/resnet_test_data_pred.csv\", names=colNames,\\\n",
    "                     header=0, parse_dates=[\"date\"])\n",
    "predDF = predDF.apply( pred_bin_out, args=(nBins,binRes,),\\\n",
    "                      axis=1 )\n",
    "predDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = predDF[\"date\"].min() - datetime.timedelta(hours=2)\n",
    "end_date = predDF[\"date\"].max()\n",
    "print start_date, end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omn_dbdir = \"../data/sqlite3/\"\n",
    "omn_db_name = \"omni_sw_imf.sqlite\"\n",
    "omn_table_name = \"imf_sw\"\n",
    "timeDelHours = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read omni data\n",
    "conn = sqlite3.connect(omn_dbdir + omn_db_name,\n",
    "                       detect_types = sqlite3.PARSE_DECLTYPES)\n",
    "# load data to a dataframe\n",
    "command = \"SELECT datetime, Bz, Vx, By FROM {tb} WHERE datetime BETWEEN '{stm}' and '{etm}'\"\n",
    "command = command.format(tb=omn_table_name,\\\n",
    "                         stm=start_date, etm=end_date)\n",
    "omnDF = pandas.read_sql(command, conn)\n",
    "# drop nan's\n",
    "omnDF.dropna(inplace=True)\n",
    "# Change the index to datetime\n",
    "omnDF.set_index(omnDF[\"datetime\"], inplace=True)\n",
    "omnDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dates from the sel type\n",
    "# and store the results in a dict!\n",
    "delTimeList = [ 2 ]\n",
    "predOmnPrfDFList = []\n",
    "for _pt in predDF[\"pred_type\"].unique():\n",
    "    selDFDates = predDF[ predDF[\"pred_type\"] == _pt ][\"date\"].tolist()\n",
    "    # Now we need the time history at each of these dates\n",
    "    for _dtl in delTimeList:\n",
    "        for _cd in selDFDates:\n",
    "            _ed =_cd - datetime.timedelta(minutes=int(_dtl*60))\n",
    "            _nd = _cd + datetime.timedelta(minutes=int(_dtl*20))\n",
    "            _resOmnDF = omnDF[ _ed : _nd ]\n",
    "            _resOmnDF[\"delTimeOnset\"] = (_resOmnDF[\"datetime\"]\\\n",
    "                                         - _cd).astype('timedelta64[m]')\n",
    "            _resOmnDF[\"pred_type\"] = _pt\n",
    "            _resOmnDF[\"pred_date\"] = _cd\n",
    "            _resOmnDF = _resOmnDF[[\"Bz\", \"Vx\", \"By\",\\\n",
    "                            \"delTimeOnset\", \"pred_date\", \"pred_type\"]]\n",
    "            \n",
    "            _resOmnDF[\"theta_c\"] = np.round(np.arctan2(_resOmnDF[\"By\"],\\\n",
    "                                            _resOmnDF[\"Bz\"]), 2) % (2*np.pi)\n",
    "            _resOmnDF[\"B_T\"] = np.sqrt(np.square(_resOmnDF[\"By\"]) + np.square(_resOmnDF[\"Bz\"]))\n",
    "            _resOmnDF[\"newell\"] =  (_resOmnDF[\"Vx\"]**(4./3)) * (_resOmnDF[\"B_T\"] ** (2./3)) * (np.sin(_resOmnDF[\"theta_c\"] / 2.))**(8./3)\n",
    "            \n",
    "            _resOmnDF.reset_index(inplace=True, drop=True)\n",
    "            predOmnPrfDFList.append( _resOmnDF )\n",
    "            \n",
    "predOmnPrflDF = pandas.concat(predOmnPrfDFList)\n",
    "predOmnPrflDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predOmnPrflDF.to_csv(\"../data/omn_cplng_profile_cat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanParamDF = predOmnPrflDF[\\\n",
    "                    [\"Bz\", \"Vx\", \"By\", \"delTimeOnset\", \"pred_type\"]\\\n",
    "                    ].groupby( [\"delTimeOnset\", \"pred_type\"] ).mean().reset_index()\n",
    "meanParamDF.columns = [\"delTimeOnset\", \"pred_type\", \"mean_Bz\", \"mean_Vx\", \"mean_By\"]\n",
    "stdParamDF = predOmnPrflDF[\\\n",
    "                    [\"Bz\", \"Vx\", \"By\", \"delTimeOnset\", \"pred_type\"]\\\n",
    "                    ].groupby( [\"delTimeOnset\", \"pred_type\"] ).std().reset_index()\n",
    "stdParamDF.columns = [\"delTimeOnset\", \"pred_type\", \"std_Bz\", \"std_Vx\", \"std_By\"]\n",
    "meanParamDF = pandas.merge( meanParamDF, stdParamDF, on=[\"delTimeOnset\", \"pred_type\"] )\n",
    "meanParamDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "predTypeList = [ \"TP\", \"FP\", \"FN\", \"TN\" ]\n",
    "f = plt.figure(figsize=(12, 8))\n",
    "ax = f.add_subplot(1,1,1)\n",
    "\n",
    "for _pd in predTypeList:\n",
    "    selDF = meanParamDF[ meanParamDF[\"pred_type\"] == _pd ]\n",
    "    ax.scatter( selDF[\"delTimeOnset\"].values, selDF[\"mean_Bz\"].values, label=_pd )\n",
    "    ax.errorbar( selDF[\"delTimeOnset\"].values, selDF[\"mean_Bz\"].values,\\\n",
    "               yerr=selDF[\"std_Bz\"].values, label='', capthick=2., capsize=5., fmt='o')\n",
    "plt.legend()\n",
    "f.savefig(\"../plots/epoch_pred_types_Bz_median.pdf\")\n",
    "f.savefig(\"../plots/epoch_pred_types_Bz_median.eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "predTypeList = [ \"TP\", \"FP\", \"FN\", \"TN\" ]\n",
    "f = plt.figure(figsize=(12, 8))\n",
    "ax = f.add_subplot(1,1,1)\n",
    "\n",
    "for _pd in predTypeList:\n",
    "    selDF = meanParamDF[ meanParamDF[\"pred_type\"] == _pd ]\n",
    "    ax.scatter( selDF[\"delTimeOnset\"].values, selDF[\"mean_Vx\"].values, label=_pd )\n",
    "#     ax.errorbar( selDF[\"delTimeOnset\"].values, selDF[\"mean_Vx\"].values,\\\n",
    "#                yerr=selDF[\"std_Vx\"].values, label='', capthick=2., capsize=5., fmt='o')\n",
    "plt.legend()\n",
    "f.savefig(\"../plots/epoch_pred_types_Vx_median.pdf\")\n",
    "f.savefig(\"../plots/epoch_pred_types_Vx_median.eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "predTypeList = [ \"TP\", \"FP\", \"FN\", \"TN\" ]\n",
    "f = plt.figure(figsize=(12, 8))\n",
    "ax = f.add_subplot(1,1,1)\n",
    "\n",
    "for _pd in predTypeList:\n",
    "    selDF = meanParamDF[ meanParamDF[\"pred_type\"] == _pd ]\n",
    "    ax.scatter( selDF[\"delTimeOnset\"].values, selDF[\"mean_By\"].values, label=_pd )\n",
    "#     ax.errorbar( selDF[\"delTimeOnset\"].values, selDF[\"mean_By\"].values,\\\n",
    "#                yerr=selDF[\"std_By\"].values, label='', capthick=2., capsize=5., fmt='o')\n",
    "plt.legend()\n",
    "f.savefig(\"../plots/epoch_pred_types_By_median.pdf\")\n",
    "f.savefig(\"../plots/epoch_pred_types_By_median.eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin by delTBins\n",
    "delTBins = range(-120,10,5)\n",
    "# get the min al in the next 30 min\n",
    "oldColNames = predOmnPrflDF.columns.tolist()\n",
    "predDF2 = pandas.concat( [ predOmnPrflDF, \\\n",
    "                    pandas.cut( predOmnPrflDF[\"delTimeOnset\"], \\\n",
    "                               bins=delTBins ) ], axis=1 )\n",
    "predDF2.columns = oldColNames + [\"delT_bin\"]\n",
    "predDF2 = predDF2[ predDF2[\"pred_type\"].isin([ \"TP\", \"FP\", \"FN\", \"TN\"]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "predTypeList = [ \"TP\", \"FP\", \"FN\", \"TN\" ]\n",
    "f = plt.figure(figsize=(12, 8))\n",
    "ax = f.add_subplot(1,1,1)\n",
    "\n",
    "sns.boxplot(x=\"delT_bin\", y=\"Bz\", hue=\"pred_type\", hue_order=predTypeList,\\\n",
    "                  data=predDF2, showfliers=False,ax=ax, linewidth=0.,\\\n",
    "            notch=True, width=0.5)\n",
    "\n",
    "ax.set_ylim([-5,2])\n",
    "plt.xticks(rotation=45)\n",
    "f.savefig(\"../plots/epoch_pred_types_Bz_boxplot.pdf\")\n",
    "f.savefig(\"../plots/epoch_pred_types_Bz_boxplot.eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omn_dbdir = \"../data/sqlite3/\"\n",
    "# omn_db_name = \"smu_sml_sme.sqlite\"\n",
    "# omn_table_name = \"smusmlsme\"\n",
    "# conn = sqlite3.connect(omn_dbdir + omn_db_name,\n",
    "#                        detect_types = sqlite3.PARSE_DECLTYPES)\n",
    "# # load data to a dataframe\n",
    "# command = \"SELECT datetime, al, ae, au FROM {tb} WHERE datetime BETWEEN '{stm}' and '{etm}'\"\n",
    "# command = command.format(tb=omn_table_name,\\\n",
    "#                          stm=start_date, etm=end_date)\n",
    "# smlDF = pandas.read_sql(command, conn)\n",
    "# # drop nan's\n",
    "# smlDF.dropna(inplace=True)\n",
    "# smlDF.set_index(smlDF[\"datetime\"], inplace=True)\n",
    "# smlDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sml_vars(row):\n",
    "#     \"\"\"\n",
    "#     Get mean, median, std, min and max of sml \n",
    "#     during various substorms over the next interval range.\n",
    "#     \"\"\"\n",
    "#     delTimeList = [30, 60]#[ 15, 30, 60, 120 ]\n",
    "#     for _dtl in delTimeList:\n",
    "#         _pd = row[\"pred_date\"] - datetime.timedelta(minutes=10)\n",
    "#         _cd = row[\"pred_date\"] + datetime.timedelta(minutes=1)\n",
    "#         _ed = row[\"pred_date\"] + datetime.timedelta(minutes=_dtl)\n",
    "#         _resDF = smlDF[ _cd : _ed ]\n",
    "#         _baselineAl = smlDF[ _pd : _cd ][\"al\"].median()\n",
    "#         _baselineAe = smlDF[ _pd : _cd ][\"ae\"].median()\n",
    "#         row[\"mean_al_\" + str(_dtl)] = _resDF[\"al\"].mean()\n",
    "#         row[\"median_al_\" + str(_dtl)] = _resDF[\"al\"].median()\n",
    "#         row[\"min_al_\" + str(_dtl)] = _resDF[\"al\"].min()\n",
    "#         row[\"max_al_\" + str(_dtl)] = _resDF[\"al\"].max()\n",
    "#         # difference between current AL and minimum in the next bin\n",
    "#         # note this is defined to be negative, for easy binning etc\n",
    "#         row[\"al_dip\" + str(_dtl)] = _resDF[\"al\"].min() - _baselineAl\n",
    "#         row[\"ae_dip\" + str(_dtl)] = _resDF[\"ae\"].max() - _baselineAe\n",
    "#     return row\n",
    "\n",
    "# predDF2 = predDF2.apply( get_sml_vars, axis=1 )\n",
    "# predDF2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predOmnPrflDF.to_csv(\"../data/omn_sml_profile_cat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
